---
typora-copy-images-to: picture
---

## 李晓旭硕士论文及相关

### 知识点

#### 一些名词

- 果梗：连接果实与植株主体的那段茎
- 果萼：

- 波数：波长的倒数

#### 近红外光谱数据

- 波数起始点为3999.64，波数之间间隔为固定的**3.8570**

### 工作

- 研究同一苹果不同部位近红外光谱的差异程度，得出结论：不同部位差异性不大，果梗果萼位置除外（其实在我看来可能只是有衰减）
- 研究同一苹果不同颜色区域近红外光谱的差异程度，得出结论：颜色没影响（好像不太对）
- 建立偏最小二乘、bp神经网络和svm的预测模型，其中bp效果最好，采用了3层网络，隐层32个节点，输入进行了主成分分析等预处理

### 存疑点

- 论文p3、p18、p25、p26、



## 相关英文

- 可溶性固形物含量： soluble solids content
- 近红外光谱：near infrared spectroscopy



## 相关算法

### PLS（偏最小二乘回归）

- 现代意义上的**回归**，是研究因变量对自变量的依赖关系的一种统计分析方法，目的是通过自变量的给定值来估计或预测因变量的均值。它可用于预测、时间序列建模以及发现各种变量之间的因果关系。简单地说，回归就是去分析因变量与自变量之间的关系，从而为分析数据、预测数据提供科学的、合理的方法。
- 自变量（Independent variable）一词来自数学。在数学中，y=f（x），在这一方程中自变量是x，因变量是y。将这个方程运用到心理学的研究中，自变量是指研究者主动操纵，而引起因变量发生变化的因素或条件，因此自变量被看作是因变量的原因。
- ![1569315848810](.\picture\1569315848810.png)

- ![1569322048952](.\picture\1569322048952.png)
- 具体： [【建模应用】PLS偏最小二乘回归原理与应用 - YD - 博客园.pdf](file\[建模应用]PLS偏最小二乘回归原理与应用 - YD - 博客园.pdf) 



## 代码尝试和一些实验

### alex分类

```matlab
d='C:\apple2';
cd(d)
temp=xlsread('data439.xlsx');
temp=temp';
temp=sortrows(temp,2);
temp=temp';
temp1=temp(4:end,:);
fdc=0.5;
[ d,p_delta ] = clustering_alex( temp1,fdc );
image(d)
plot(p_delta(1,:),p_delta(2,:),'o')
xlswrite('temp.xls', temp);
```

plot(temp(2,:)):

![Snipaste_2019-09-10_13-17-08](.\picture\Snipaste_2019-09-10_13-17-08.png)

image(d):

![Snipaste_2019-09-10_12-40-42](.\picture\Snipaste_2019-09-10_12-40-42.png)

fdc=0.5  plot(p_delta(1,:),p_delta(2,:),'o'):

![Snipaste_2019-09-10_12-45-26](.\picture\Snipaste_2019-09-10_12-45-26.png)

fdc=0.1  plot(p_delta(1,:),p_delta(2,:),'o'):

![Snipaste_2019-09-10_12-51-57](.\picture\Snipaste_2019-09-10_12-51-57.png)

fdc=1  plot(p_delta(1,:),p_delta(2,:),'o'):

![Snipaste_2019-09-10_12-53-17](.\picture\Snipaste_2019-09-10_12-53-17.png)

### SAE分类

```matlab
d='C:\apple2';
cd(d)
temp=xlsread('data439.xlsx');
temp=temp';
temp=sortrows(temp,2);
temp1=temp(:,4:end);
x=temp1;x=x';
y=temp(:,2);y=y';
mean_x=mean(x);    %均值中心化-求均值
for i=1:size(x,1)
x(i,:)=x(i,:)-mean_x;  %均值中心化
end

rand('state',0)
sae = saesetup([1557 500 200 60 30]);
sae.ae{1}.activation_function       = 'sigm';
sae.ae{1}.learningRate              = 1;
sae.ae{1}.inputZeroMaskedFraction   = 0.5;
opts.numepochs =   10;
opts.batchsize = 256;
sae = saetrain(sae, x, opts);
%visualize(sae.ae{1}.W{1}(:,2:end)')

% Use the SDAE to initialize a FFNN
nn = nnsetup([1557 500 200 60 30 1]);
nn.activation_function              = 'sigm';
nn.learningRate                     = 1;
nn.W{1} = sae.ae{1}.W{1};

% Train the FFNN
opts.numepochs =   10;
opts.batchsize = 256;
nn = nntrain(nn, x, y, opts);
[er, bad] = nntest(nn, x, y);
assert(er < 0.16, 'Too big error');
```



### 数据的特性观察

```matlab
%斜率
d='C:\apple2';
cd(d)
temp=xlsread('data439.xlsx');
temp=temp';
temp=sortrows(temp,2);
temp1=temp(:,4:end);
for i=1:size(temp1,2)-1
temp2(:,i)=temp1(:,i+1)-temp1(:,i);
end

```



### PLS的matlab代码：

```matlab
d='C:\apple2';
cd(d)
clc,clear
load pz.mat %原始数据存放在纯文本文件 pz.mat 中
mu=mean(pz);sig=std(pz); %求均值和标准差
rr=corrcoef(pz); %求相关系数矩阵
data=zscore(pz); %数据标准化,变量记做 X*和 Y*
n=3;m=3; %n 是自变量的个数,m 是因变量的个数
x0=pz(:,1:n);y0=pz(:,n+1:end); %原始的自变量和因变量数据
e0=data(:,1:n);f0=data(:,n+1:end); %标准化后的自变量和因变量数据
%%
num=size(e0,1);%求样本点的个数
chg=eye(n); %w 到 w*变换矩阵的初始化
for i=1:n
%以下计算 w，w*和 t 的得分向量，
matrix=e0'*f0*f0'*e0;
[vec,val]=eig(matrix); %求特征值和特征向量
val=diag(val); %提出对角线元素，即提出特征值
[val,ind]=sort(val,'descend');
w(:,i)=vec(:,ind(1)); %提出最大特征值对应的特征向量
w_star(:,i)=chg*w(:,i); %计算 w*的取值
t(:,i)=e0*w(:,i); %计算成分 ti 的得分
alpha=e0'*t(:,i)/(t(:,i)'*t(:,i)); %计算 alpha_i
chg=chg*(eye(n)-w(:,i)*alpha'); %计算 w 到 w*的变换矩阵
e=e0-t(:,i)*alpha'; %计算残差矩阵
e0=e;
%以下计算 ss(i)的值
beta=t\f0; %求回归方程的系数，数据标准化，没有常数项
cancha=f0-t*beta; %求残差矩阵
ss(i)=sum(sum(cancha.^2)); %求误差平方和
%以下计算 press(i)
for j=1:num
t1=t(:,1:i);f1=f0;
she_t=t1(j,:);she_f=f1(j,:); %把舍去的第 j 个样本点保存起来
t1(j,:)=[];f1(j,:)=[]; %删除第 j 个观测值
beta1=[t1,ones(num-1,1)]\f1; %求回归分析的系数,这里带有常数项
cancha=she_f-she_t*beta1(1:end-1,:)-beta1(end,:); %求残差向量
press_i(j)=sum(cancha.^2); %求误差平方和
end
press(i)=sum(press_i);
Q_h2(1)=1;
if i>1
Q_h2(i)=1-press(i)/ss(i-1); 
end
if Q_h2(i)<0.0975
fprintf('提出的成分个数 r=%d',i); break
end
end
beta_z=t\f0; %求 Y*关于 t 的回归系数
xishu=w_star*beta_z; %求 Y*关于 X*的回归系数，每一列是一个回归方程
mu_x=mu(1:n);mu_y=mu(n+1:end); %提出自变量和因变量的均值
sig_x=sig(1:n);sig_y=sig(n+1:end); %提出自变量和因变量的标准差
ch0=mu_y-(mu_x./sig_x*xishu).*sig_y; %计算原始数据回归方程的常数项
for i=1:m
xish(:,i)=xishu(:,i)./sig_x'*sig_y(i); %计算原始数据回归方程的系数
end
sol=[ch0;xish] %显示回归方程的系数，每一列是一个方程，每一列的第一个数是常数项
save mydata x0 y0 num xishu ch0 xish

```



### PLS直接拟合近红外

```matlab
d='C:\apple2';
cd(d)
temp=xlsread('data439.xlsx');
ls=temp(2,:);
temp(1:3,:)=[];
mean_temp=mean(temp);    %均值中心化-求均值
for i=1:size(temp,1)
temp(i,:)=temp(i,:)-mean_temp;  %均值中心化
end
temp=[temp;ls];
temp=temp';
train=temp(1:300,:);
verify=temp(301:380,:);
test=temp(381:439,:);
[data, w_star, beta_z, sol]=PLSmade(train,1557);
train_x=train(:,1:1557);train_y=train(:,1558);
y=[ones(size(train_x,1),1),train_x]*sol;
r_c=sqrt(sum((y-train_y).^2))/(sqrt(sum((y-mean(train_y)).^2))); %计算相关系数
plot(y,train_y,'*r')   %画出预测值与实际值的相关关系
RMSEC=sqrt(sum((y-train_y).^2)/size(y,1));  %计算均方根误差
```

### PLS-BPNN拟合近红外

```matlab
d='C:\apple2';
cd(d)
temp=xlsread('data439.xlsx');
ls=temp(2,:);
temp(1:3,:)=[];
mean_temp=mean(temp);    %均值中心化-求均值
for i=1:size(temp,1)
temp(i,:)=temp(i,:)-mean_temp;  %均值中心化
end
temp=[temp;ls];
temp=temp';
train=temp(1:300,:);
verify=temp(301:380,:);
test=temp(381:439,:);
[data, w_star, beta_z, sol]=PLSmade(train,1557);
%构建bp
data_x=data(:,1:1557);data_y=data(:,1558);
data_x=data_x./10;data_y=data_y./10;
rand('state',0)
nn = nnsetup([size(data_x,2) size(w_star,2) size(beta_z,2)]);
nn.momentum  = 0;
nn.sparsityTarget = 0;
opts.numepochs = 100;
opts.batchsize = 300; 
nn.learningRate = 0.0001;
nn.output = 'linear';
%nn.activation_function = 'linear';
nn.W{1}=[zeros(1,size(w_star,2));w_star]';
nn.W{2}=[zeros(1,size(beta_z,2));beta_z]';
[nn, L] = nntrain(nn, data_x, data_y, opts);
mu=mean(train);sig=std(train); %求均值和标准差
y=sig(end)*nn.a{end}+mu(end);
```















































## 论文阅读

![1569481500950](.\picture\1569481500950.png)

1. PLS+CARS，研究了测量位置对苹果SSC测量的影响
2. 研究了脐橙不同放置位置对脐橙可溶性固形物含量的影响，采用偏最小二乘回归结合不同的预处理方法
3. 采用蚁群优化算法结合偏最小二乘法（ACO-PLS）对不同地理区域苹果可溶性固形物（SSC）的近红外光谱特征波长进行选择
4. 目的是减小产地对SSC测量的影响。采用偏最小二乘法（pls）建立了苹果ssc的局部起源和混合起源模型。采用竞争自适应加权采样（cars）和连续投影算法（spa）对苹果ssc的近红外光谱进行有效变量选择
5. 旋转苹果测量，PLS+PCA（主成分分析）
6. 





















